{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARGIN = 10  # pixels\n",
    "FONT_SIZE = 1\n",
    "FONT_THICKNESS = 1\n",
    "HANDEDNESS_TEXT_COLOR = (88, 205, 54) # vibrant green\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "    hand_landmarks_list = detection_result.hand_landmarks\n",
    "    handedness_list = detection_result.handedness\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "    # Loop through the detected hands to visualize.\n",
    "    for idx in range(len(hand_landmarks_list)):\n",
    "        hand_landmarks = hand_landmarks_list[idx]\n",
    "        handedness = handedness_list[idx]\n",
    "        # Draw the hand landmarks.\n",
    "        hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        hand_landmarks_proto.landmark.extend([\n",
    "          landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "        ])\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "          annotated_image,\n",
    "          hand_landmarks_proto,\n",
    "          solutions.hands.HAND_CONNECTIONS,\n",
    "          solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "          solutions.drawing_styles.get_default_hand_connections_style())\n",
    "        # Get the top left corner of the detected hand's bounding box.\n",
    "        height, width, _ = annotated_image.shape\n",
    "        x_coordinates = [landmark.x for landmark in hand_landmarks]\n",
    "        y_coordinates = [landmark.y for landmark in hand_landmarks]\n",
    "        text_x = int(min(x_coordinates) * width)\n",
    "        text_y = int(min(y_coordinates) * height) - MARGIN\n",
    "        # Draw handedness (left or right hand) on the image.\n",
    "        cv2.putText(annotated_image, f\"{handedness[0].category_name}\",\n",
    "                    (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n",
    "    return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup options\n",
    "base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "options = vision.HandLandmarkerOptions(base_options=base_options, num_hands=2)\n",
    "detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "# Get inference\n",
    "def get_annotation_from(frame):\n",
    "    image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "    detection_result = detector.detect(image)\n",
    "    \n",
    "    # annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
    "    # return detection_result, annotated_image\n",
    "    return detection_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gesture(hand_landmarks):\n",
    "        thumb_tip = hand_landmarks.landmark[4]\n",
    "        index_finger_tip = hand_landmarks.landmark[8]\n",
    "        middle_finger_tip = hand_landmarks.landmark[12]\n",
    "        ring_finger_tip = hand_landmarks.landmark[16]\n",
    "        little_finger_tip = hand_landmarks.landmark[20]\n",
    "\n",
    "        # Check if hand is in OK gesture\n",
    "        if thumb_tip.y < index_finger_tip.y < middle_finger_tip.y < ring_finger_tip.y < little_finger_tip.y:\n",
    "            print(\"Okay\")\n",
    "            # return \"Okay\"\n",
    "\n",
    "        # Check if hand is in Dislike gesture\n",
    "        elif thumb_tip.y > index_finger_tip.y > middle_finger_tip.y > ring_finger_tip.y > little_finger_tip.y:\n",
    "            print(\"Dislike\")\n",
    "            # return \"Dislike\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[NormalizedLandmark(x=0.3775796592235565, y=0.4484468698501587, z=-7.658888421246957e-07, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.45659855008125305, y=0.5906875729560852, z=-0.12274359911680222, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.5610436201095581, y=0.7097854614257812, z=-0.21682056784629822, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6087026596069336, y=0.8151220083236694, z=-0.296338826417923, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6378511190414429, y=0.908829927444458, z=-0.35788753628730774, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.8904979825019836, y=0.6001406311988831, z=-0.19998541474342346, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.7954009175300598, y=0.6598494052886963, z=-0.3039839267730713, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6656880378723145, y=0.6365615129470825, z=-0.335548996925354, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6671821475028992, y=0.6085880398750305, z=-0.35445836186408997, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.898669421672821, y=0.5096270442008972, z=-0.19526363909244537, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.75278240442276, y=0.5814493298530579, z=-0.2936910390853882, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.612981379032135, y=0.5601851940155029, z=-0.3004629611968994, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6546536087989807, y=0.5412085056304932, z=-0.30732816457748413, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.8554795980453491, y=0.4279521703720093, z=-0.20076903700828552, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.7269594669342041, y=0.4955122172832489, z=-0.2942810356616974, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6094602346420288, y=0.4916418492794037, z=-0.26329225301742554, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6465423703193665, y=0.47868800163269043, z=-0.24249880015850067, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.7972978353500366, y=0.35576874017715454, z=-0.21797560155391693, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6930086612701416, y=0.40036165714263916, z=-0.27921369671821594, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6115598678588867, y=0.4121805429458618, z=-0.2648589015007019, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6311843395233154, y=0.40035271644592285, z=-0.25259679555892944, visibility=0.0, presence=0.0)]]\n"
     ]
    }
   ],
   "source": [
    "# define a video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "  \n",
    "base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "options = vision.HandLandmarkerOptions(base_options=base_options, num_hands=2)\n",
    "detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "# while True:\n",
    "#     # capture image\n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "#     if ret:\n",
    "#         # detection_result, annotation = get_annotation_from(frame)\n",
    "#         # cv2.imshow('', annotation)  \n",
    "#         # print(detection_result)\n",
    "#         image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "#         detection_result = detector.detect(image)\n",
    "#         print(detection_result)\n",
    "#     else:\n",
    "#         print(\"! No frame\")\n",
    "        \n",
    "#     time.sleep(1)\n",
    "     \n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "\n",
    "ret, frame = cap.read()\n",
    "    \n",
    "if ret:\n",
    "    # image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "    image = mp.Image.create_from_file('thumbs_down.jpg')\n",
    "    detection_result = detector.detect(image)\n",
    "    hand_landmarks_list = detection_result.hand_landmarks\n",
    "    print(hand_landmarks_list)\n",
    "    # handedness_list = detection_result.handedness\n",
    "    # get_gesture()\n",
    "    # print(detection_result.hand_landmarks)\n",
    "else:\n",
    "    print(\"! No frame\")\n",
    "\n",
    "\n",
    "\n",
    "# After the loop release the cap object\n",
    "cap.release()\n",
    "\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
